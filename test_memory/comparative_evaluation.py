"""
è®°å¿†ç³»ç»Ÿå¯¹æ¯”è¯„æµ‹ç¨‹åº

åŒæ—¶å¯¹MemoBaseå’ŒMemuä¸¤ä¸ªè®°å¿†ç³»ç»Ÿè¿›è¡Œè¯„æµ‹ï¼Œå¹¶ç”Ÿæˆå¯¹æ¯”åˆ†ææŠ¥å‘Š
"""

import os
import sys
from typing import Dict, List, Any
from datetime import datetime
import json

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(__file__))

try:
    from test_memobase.memory_evaluator import MemoryEvaluator as MemoBaseEvaluator
    from test_memu.memu_evaluator import MemuEvaluator
    EVALUATORS_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸ å¯¼å…¥è¯„æµ‹å™¨å¤±è´¥: {e}")
    EVALUATORS_AVAILABLE = False


class ComparativeEvaluator:
    """è®°å¿†ç³»ç»Ÿå¯¹æ¯”è¯„æµ‹å™¨"""
    
    def __init__(self):
        if not EVALUATORS_AVAILABLE:
            raise RuntimeError("æ— æ³•å¯¼å…¥å¿…è¦çš„è¯„æµ‹å™¨æ¨¡å—")
        
        self.memobase_evaluator = None
        self.memu_evaluator = None
        self.results = {}
    
    def run_memobase_evaluation(self) -> Dict[str, Any]:
        """è¿è¡ŒMemoBaseè¯„æµ‹"""
        print("ğŸš€ å¼€å§‹MemoBaseè®°å¿†ç³»ç»Ÿè¯„æµ‹...")
        print("=" * 60)
        
        try:
            self.memobase_evaluator = MemoBaseEvaluator()
            
            # è®¾ç½®æµ‹è¯•ç¯å¢ƒä½†ä¸æ’å…¥æ•°æ®ï¼ˆé¿å…é‡å¤æ’å…¥ï¼‰
            self.memobase_evaluator.setup_test_user()
            
            # æ‰§è¡Œè¯„æµ‹
            results = self.memobase_evaluator.evaluate_all_scenarios()
            
            print("âœ… MemoBaseè¯„æµ‹å®Œæˆ!\n")
            return results
            
        except Exception as e:
            print(f"âŒ MemoBaseè¯„æµ‹å¤±è´¥: {e}")
            return {
                "error": str(e),
                "memory_framework": "MemoBase",
                "evaluation_timestamp": datetime.now().isoformat(),
                "overall_average": 0.0,
                "total_test_cases": 0
            }
    
    def run_memu_evaluation(self) -> Dict[str, Any]:
        """è¿è¡ŒMemuè¯„æµ‹"""
        print("ğŸš€ å¼€å§‹Memuè®°å¿†ç³»ç»Ÿè¯„æµ‹...")
        print("=" * 60)
        
        try:
            self.memu_evaluator = MemuEvaluator()
            
            # è®¾ç½®æµ‹è¯•æ•°æ®
            self.memu_evaluator.setup_test_data()
            
            # æ‰§è¡Œè¯„æµ‹
            results = self.memu_evaluator.evaluate_all_scenarios()
            
            print("âœ… Memuè¯„æµ‹å®Œæˆ!\n")
            return results
            
        except Exception as e:
            print(f"âŒ Memuè¯„æµ‹å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return {
                "error": str(e),
                "memory_framework": "Memu",
                "evaluation_timestamp": datetime.now().isoformat(),
                "overall_average": 0.0,
                "total_test_cases": 0
            }
    
    def generate_comparative_report(self, memobase_results: Dict[str, Any], memu_results: Dict[str, Any]) -> str:
        """ç”Ÿæˆå¯¹æ¯”è¯„æµ‹æŠ¥å‘Š"""
        
        report = []
        report.append("=" * 100)
        report.append("ğŸ§  è®°å¿†ç³»ç»Ÿå¯¹æ¯”è¯„æµ‹æŠ¥å‘Š")
        report.append("=" * 100)
        report.append(f"è¯„æµ‹æ—¶é—´: {datetime.now().isoformat()}")
        report.append(f"MemoBaseæµ‹è¯•ç”¨ä¾‹: {memobase_results.get('total_test_cases', 0)}")
        report.append(f"Memuæµ‹è¯•ç”¨ä¾‹: {memu_results.get('total_test_cases', 0)}")
        report.append("")
        
        # æ•´ä½“å¯¹æ¯”
        report.append("ğŸ“Š æ•´ä½“æ€§èƒ½å¯¹æ¯”")
        report.append("-" * 60)
        
        memobase_avg = memobase_results.get('overall_average', 0.0)
        memu_avg = memu_results.get('overall_average', 0.0)
        
        report.append(f"{'è®°å¿†ç³»ç»Ÿ':<15} {'ç»¼åˆå¾—åˆ†':<10} {'Context/èšç±»':<12} {'Profile/è®°å¿†é¡¹ç›®':<15}")
        report.append("-" * 60)
        
        # MemoBaseç»“æœ
        memobase_context = memobase_results.get('overall_context_avg', 0.0)
        memobase_profile = memobase_results.get('overall_profile_avg', 0.0)
        report.append(f"{'MemoBase':<15} {memobase_avg:<10.2f} {memobase_context:<12.2f} {memobase_profile:<15.2f}")
        
        # Memuç»“æœ
        memu_clustered = memu_results.get('overall_clustered_avg', 0.0)
        memu_memory = memu_results.get('overall_memory_items_avg', 0.0)
        report.append(f"{'Memu':<15} {memu_avg:<10.2f} {memu_clustered:<12.2f} {memu_memory:<15.2f}")
        
        # æ€§èƒ½å·®å¼‚åˆ†æ
        report.append("")
        report.append("ğŸ“ˆ æ€§èƒ½å·®å¼‚åˆ†æ")
        report.append("-" * 60)
        
        if memobase_avg > memu_avg:
            winner = "MemoBase"
            advantage = memobase_avg - memu_avg
        elif memu_avg > memobase_avg:
            winner = "Memu"
            advantage = memu_avg - memobase_avg
        else:
            winner = "å¹³åˆ†"
            advantage = 0.0
        
        report.append(f"ğŸ† ç»¼åˆæ€§èƒ½ä¼˜èƒœ: {winner}")
        if advantage > 0:
            report.append(f"ğŸ“Š æ€§èƒ½ä¼˜åŠ¿: {advantage:.2f} åˆ† ({advantage/10*100:.1f}%)")
        
        # å„ç»´åº¦å¯¹æ¯”
        report.append("")
        report.append("ğŸ” å„ç»´åº¦è¯¦ç»†å¯¹æ¯”")
        report.append("-" * 60)
        
        # Context vs èšç±»åˆ†ç±»
        context_diff = memobase_context - memu_clustered
        if abs(context_diff) > 0.5:
            context_winner = "MemoBase Contextæ£€ç´¢" if context_diff > 0 else "Memu èšç±»åˆ†ç±»æ£€ç´¢"
            report.append(f"æ£€ç´¢ç»´åº¦1: {context_winner} é¢†å…ˆ {abs(context_diff):.2f} åˆ†")
        else:
            report.append("æ£€ç´¢ç»´åº¦1: MemoBase Contextæ£€ç´¢ vs Memu èšç±»åˆ†ç±»æ£€ç´¢ - æ€§èƒ½ç›¸å½“")
        
        # Profile vs è®°å¿†é¡¹ç›®
        profile_diff = memobase_profile - memu_memory
        if abs(profile_diff) > 0.5:
            profile_winner = "MemoBase Profileæ£€ç´¢" if profile_diff > 0 else "Memu è®°å¿†é¡¹ç›®æ£€ç´¢"
            report.append(f"æ£€ç´¢ç»´åº¦2: {profile_winner} é¢†å…ˆ {abs(profile_diff):.2f} åˆ†")
        else:
            report.append("æ£€ç´¢ç»´åº¦2: MemoBase Profileæ£€ç´¢ vs Memu è®°å¿†é¡¹ç›®æ£€ç´¢ - æ€§èƒ½ç›¸å½“")
        
        # åœºæ™¯çº§å¯¹æ¯”åˆ†æ
        if ("scenario_results" in memobase_results and "scenario_results" in memu_results):
            report.append("")
            report.append("ğŸ¯ åœºæ™¯çº§æ€§èƒ½å¯¹æ¯”")
            report.append("-" * 60)
            
            memobase_scenarios = memobase_results["scenario_results"]
            memu_scenarios = memu_results["scenario_results"]
            
            scenario_comparison = []
            
            for scenario_name in memobase_scenarios.keys():
                if scenario_name in memu_scenarios:
                    mb_score = memobase_scenarios[scenario_name]["scenario_overall_avg"]
                    mu_score = memu_scenarios[scenario_name]["scenario_overall_avg"]
                    
                    diff = mb_score - mu_score
                    if abs(diff) > 0.5:
                        winner = "MemoBase" if diff > 0 else "Memu"
                        scenario_comparison.append({
                            "scenario": scenario_name,
                            "winner": winner,
                            "mb_score": mb_score,
                            "mu_score": mu_score,
                            "diff": abs(diff)
                        })
            
            # æ˜¾ç¤ºæœ‰æ˜¾è‘—å·®å¼‚çš„åœºæ™¯
            if scenario_comparison:
                report.append("æ˜¾è‘—æ€§èƒ½å·®å¼‚çš„åœºæ™¯:")
                for comp in sorted(scenario_comparison, key=lambda x: x["diff"], reverse=True)[:3]:
                    report.append(f"  {comp['scenario']}: {comp['winner']} é¢†å…ˆ {comp['diff']:.2f}åˆ†")
                    report.append(f"    MemoBase: {comp['mb_score']:.2f}, Memu: {comp['mu_score']:.2f}")
        
        # é”™è¯¯ä¿¡æ¯
        if "error" in memobase_results:
            report.append("")
            report.append("âŒ MemoBaseè¯„æµ‹é”™è¯¯:")
            report.append(f"   {memobase_results['error']}")
        
        if "error" in memu_results:
            report.append("")
            report.append("âŒ Memuè¯„æµ‹é”™è¯¯:")
            report.append(f"   {memu_results['error']}")
        
        # è¯„æµ‹å»ºè®®
        report.append("")
        report.append("ğŸ’¡ è¯„æµ‹å»ºè®®")
        report.append("-" * 60)
        
        if memobase_avg > 7.0 or memu_avg > 7.0:
            report.append("âœ… ä¸¤ä¸ªè®°å¿†ç³»ç»Ÿéƒ½è¡¨ç°è‰¯å¥½ï¼Œå¯æ ¹æ®å…·ä½“åœºæ™¯éœ€æ±‚é€‰æ‹©")
        elif max(memobase_avg, memu_avg) > 5.0:
            report.append("âš ï¸ è®°å¿†ç³»ç»Ÿæœ‰ä¸€å®šæ•ˆæœï¼Œä½†ä»æœ‰ä¼˜åŒ–ç©ºé—´")
        else:
            report.append("âŒ è®°å¿†ç³»ç»Ÿæ•ˆæœæœ‰å¾…æ”¹è¿›ï¼Œå»ºè®®æ£€æŸ¥æ•°æ®è´¨é‡å’Œæ£€ç´¢ç®—æ³•")
        
        if abs(memobase_avg - memu_avg) < 1.0:
            report.append("ğŸ¤ ä¸¤ç³»ç»Ÿæ€§èƒ½ç›¸è¿‘ï¼Œå¯è€ƒè™‘æ··åˆä½¿ç”¨æˆ–æ ¹æ®æˆæœ¬é€‰æ‹©")
        
        report.append("")
        report.append("=" * 100)
        
        return "\n".join(report)
    
    def save_comparative_results(self, memobase_results: Dict[str, Any], memu_results: Dict[str, Any]) -> None:
        """ä¿å­˜å¯¹æ¯”è¯„æµ‹ç»“æœ"""
        
        comparative_data = {
            "evaluation_timestamp": datetime.now().isoformat(),
            "memobase_results": memobase_results,
            "memu_results": memu_results,
            "comparison_summary": {
                "memobase_overall": memobase_results.get('overall_average', 0.0),
                "memu_overall": memu_results.get('overall_average', 0.0),
                "performance_difference": abs(memobase_results.get('overall_average', 0.0) - 
                                           memu_results.get('overall_average', 0.0)),
                "winner": "MemoBase" if memobase_results.get('overall_average', 0.0) > 
                         memu_results.get('overall_average', 0.0) else "Memu"
            }
        }
        
        # ä¿å­˜è¯¦ç»†å¯¹æ¯”æ•°æ®
        output_path = os.path.join(os.path.dirname(__file__), "comparative_evaluation_results.json")
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(comparative_data, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ“ å¯¹æ¯”è¯„æµ‹ç»“æœå·²ä¿å­˜è‡³: {output_path}")
    
    def run_comparative_evaluation(self) -> None:
        """è¿è¡Œå®Œæ•´çš„å¯¹æ¯”è¯„æµ‹"""
        print("ğŸ§  è®°å¿†ç³»ç»Ÿå¯¹æ¯”è¯„æµ‹ç¨‹åºå¯åŠ¨")
        print("=" * 80)
        print("æ­£åœ¨è¯„æµ‹ MemoBase å’Œ Memu ä¸¤ä¸ªè®°å¿†ç³»ç»Ÿçš„æ€§èƒ½å·®å¼‚...")
        print("")
        
        try:
            # 1. è¿è¡ŒMemoBaseè¯„æµ‹
            memobase_results = self.run_memobase_evaluation()
            
            # 2. è¿è¡ŒMemuè¯„æµ‹
            memu_results = self.run_memu_evaluation()
            
            # 3. ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
            comparative_report = self.generate_comparative_report(memobase_results, memu_results)
            print(comparative_report)
            
            # 4. ä¿å­˜ç»“æœ
            self.save_comparative_results(memobase_results, memu_results)
            
            print("âœ… è®°å¿†ç³»ç»Ÿå¯¹æ¯”è¯„æµ‹å®Œæˆ!")
            
        except Exception as e:
            print(f"âŒ å¯¹æ¯”è¯„æµ‹è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            raise


def main():
    """ä¸»å‡½æ•°"""
    if not EVALUATORS_AVAILABLE:
        print("âŒ æ— æ³•åŠ è½½è¯„æµ‹å™¨ï¼Œè¯·æ£€æŸ¥æ¨¡å—å¯¼å…¥")
        return
    
    evaluator = ComparativeEvaluator()
    evaluator.run_comparative_evaluation()


if __name__ == "__main__":
    main()